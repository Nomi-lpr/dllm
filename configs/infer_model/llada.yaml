# LLaDA模型推理配置
mask_id: 126336  # mask token的ID
# mask_length: 256  # mask token长度（修改为128）

# 模型路径配置（必需）
model_path: "/home/share/model_weight/llada/LLaDA-8B-Base/"  # 请修改为实际的模型路径
# 或者使用 model_name（如果模型在 HuggingFace Hub 上）
# model_name: "your-org/llada-model"

# 模型加载参数
trust_remote_code: true  # 是否信任远程代码
local_files_only: true  # 是否只使用本地文件
torch_dtype: "bfloat16"  # 模型精度：bfloat16, float16, float32

# # 生成参数,每个数据集都是不一样的
# generation_kwargs:
#   steps: 256  # 采样步数
#   gen_length: 256  # 生成长度
#   block_length: 256  # 块长度
#   temperature: 0.0  # 温度
#   cfg_scale: 0.0  # CFG scale
#   remasking: "low_confidence"  # 重掩码策略

# Prompt模板配置
prompt_templates:
  gsm8k_prompt_template: "question: <Q>\n<answer>\n<A>\n</answer>"  # GSM8K prompt模板，<Q>会被question替换，<A>会被完整answer替换（query时<A>用mask替换）
  mmlu_prompt_template: "<Q>\nA. <a>\nB. <b>\nC. <c>\nD. <d>\nAnswer: <A>"  # MMLU多选题模板
  ceval_prompt_template: "<Q>\nA. <a>\nB. <b>\nC. <c>\nD. <d>\nAnswer: <A>"  # C-Eval多选题模板
  cmmlu_prompt_template: "<Q>\nA. <a>\nB. <b>\nC. <c>\nD. <d>\nAnswer: <A>"  # C-MMLU多选题模板







